#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""

Connect to the REST API of a Noark 5 service and check that it behaves
as it should.  See also http://rel.arkivverket.no/noark5/konformitetsniva/

"""
# Copyright (C) 2017 Petter Reinholdtsen <pere@hungry.com>
#
# Licensed under the GNU General Public License Version 2
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.

from __future__ import print_function

import sys
import os
sys.path.append(os.path.join(sys.path[0], 'lib'))

# Enforce ASCII on stdout, also on redirect and pipes, replace
# non-ascii characters with '?'.
# sys.stdout = codecs.getwriter('ascii')(sys.stdout, errors='replace')

import argparse
import datetime
from hashlib import sha256
import json
import pytz
import re
from subprocess import call
from urllib.parse import quote_plus

import n5core.endpoint
from n5core.endpoint import HTTPError
from n5core.endpoint import URLError

noarkrelbase = 'https://rel.arkivverket.no/noark5/v5/api/'
nikitarelbase = 'https://nikita.arkivlab.no/noark5/v5/'

def utcnowtz():
    u = datetime.datetime.utcnow()
    u = u.replace(tzinfo=pytz.utc)
    return u

class Noark5Tester (n5core.endpoint.Endpoint):
    knownrels = [
        noarkrelbase + 'admin/',
        noarkrelbase + 'admin/administrativenhet/',
        noarkrelbase + 'admin/bruker/',
        noarkrelbase + 'admin/ny-administrativenhet/',
        noarkrelbase + 'admin/ny-bruker/',
        noarkrelbase + 'admin/ny-rettighet/',
        noarkrelbase + 'admin/ny-tilgang/',
        noarkrelbase + 'admin/rettighet/',
        noarkrelbase + 'admin/system/',
        noarkrelbase + 'admin/tilgang/',
        noarkrelbase + 'arkivstruktur/',
        noarkrelbase + 'arkivstruktur/arkiv/',
        noarkrelbase + 'arkivstruktur/arkivdel/',
        noarkrelbase + 'arkivstruktur/arkivskaper/',
        noarkrelbase + 'arkivstruktur/bygning/',
        noarkrelbase + 'arkivstruktur/dnummer/',
        noarkrelbase + 'arkivstruktur/dokumentbeskrivelse/',
        noarkrelbase + 'arkivstruktur/dokumentobjekt/',
        noarkrelbase + 'arkivstruktur/enhetsidentifikator/',
        noarkrelbase + 'arkivstruktur/fil/',
        noarkrelbase + 'arkivstruktur/foedselsnummer/',
        noarkrelbase + 'arkivstruktur/forrigearkivdel/',
        noarkrelbase + 'arkivstruktur/klasse/',
        noarkrelbase + 'arkivstruktur/klassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/konvertering/',
        noarkrelbase + 'arkivstruktur/korrespondansepart/',
        noarkrelbase + 'arkivstruktur/korrespondansepartenhet/',
        noarkrelbase + 'arkivstruktur/korrespondansepartintern/',
        noarkrelbase + 'arkivstruktur/korrespondansepartperson/',
        noarkrelbase + 'arkivstruktur/kryssreferanse/',
        noarkrelbase + 'arkivstruktur/mappe/',
        noarkrelbase + 'arkivstruktur/matrikkel/',
        noarkrelbase + 'arkivstruktur/merknad/',
        noarkrelbase + 'arkivstruktur/nasjonalidentifikator/',
        noarkrelbase + 'arkivstruktur/nestearkivdel/',
        noarkrelbase + 'arkivstruktur/ny-arkiv/',
        noarkrelbase + 'arkivstruktur/ny-arkivdel/',
        noarkrelbase + 'arkivstruktur/ny-arkivskaper/',
        noarkrelbase + 'arkivstruktur/ny-bygning/',
        noarkrelbase + 'arkivstruktur/ny-dnummer/',
        noarkrelbase + 'arkivstruktur/ny-dokumentbeskrivelse/',
        noarkrelbase + 'arkivstruktur/ny-dokumentobjekt/',
        noarkrelbase + 'arkivstruktur/ny-enhetsidentifikator/',
        noarkrelbase + 'arkivstruktur/ny-foedselsnummer/',
        noarkrelbase + 'arkivstruktur/ny-klasse/',
        noarkrelbase + 'arkivstruktur/ny-klassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/ny-konvertering/',
        noarkrelbase + 'arkivstruktur/ny-korrespondansepartenhet/',
        noarkrelbase + 'arkivstruktur/ny-korrespondansepartintern/',
        noarkrelbase + 'arkivstruktur/ny-korrespondansepartperson/',
        noarkrelbase + 'arkivstruktur/ny-kryssreferanse/',
        noarkrelbase + 'arkivstruktur/ny-mappe/',
        noarkrelbase + 'arkivstruktur/ny-matrikkel/',
        noarkrelbase + 'arkivstruktur/ny-merknad/',
        noarkrelbase + 'arkivstruktur/ny-partenhet/',
        noarkrelbase + 'arkivstruktur/ny-partperson/',
        noarkrelbase + 'arkivstruktur/ny-plan/',
        noarkrelbase + 'arkivstruktur/ny-posisjon/',
        noarkrelbase + 'arkivstruktur/ny-registrering/',
        noarkrelbase + 'arkivstruktur/ny-sekundaerklassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/overarkiv/',
        noarkrelbase + 'arkivstruktur/overklasse/',
        noarkrelbase + 'arkivstruktur/overmappe/',
        noarkrelbase + 'arkivstruktur/part/',
        noarkrelbase + 'arkivstruktur/partenhet/',
        noarkrelbase + 'arkivstruktur/partperson/',
        noarkrelbase + 'arkivstruktur/plan/',
        noarkrelbase + 'arkivstruktur/posisjon/',
        noarkrelbase + 'arkivstruktur/registrering/',
        noarkrelbase + 'arkivstruktur/sekundaerklassifikasjonssystem/',
        noarkrelbase + 'arkivstruktur/underarkiv/',
        noarkrelbase + 'arkivstruktur/underklasse/',
        noarkrelbase + 'arkivstruktur/undermappe/',
        noarkrelbase + 'loggingogsporing/',
        noarkrelbase + 'loggingogsporing/endringslogg/',
        noarkrelbase + 'loggingogsporing/hendelseslogg/',
        noarkrelbase + 'loggingogsporing/ny-endringslogg/',
        noarkrelbase + 'loggingogsporing/ny-hendelseslogg/',
        noarkrelbase + 'login/oidc/',
        noarkrelbase + 'metadata/',
        noarkrelbase + 'metadata/arkivdelstatus/',
        noarkrelbase + 'metadata/arkivstatus/',
        noarkrelbase + 'metadata/avskrivningsmaate/',
        noarkrelbase + 'metadata/dokumentmedium/',
        noarkrelbase + 'metadata/dokumentstatus/',
        noarkrelbase + 'metadata/dokumenttype/',
        noarkrelbase + 'metadata/elektronisksignatursikkerhetsnivaa/',
        noarkrelbase + 'metadata/elektronisksignaturverifisert/',
        noarkrelbase + 'metadata/flytstatus/',
        noarkrelbase + 'metadata/format/',
        noarkrelbase + 'metadata/graderingskode/',
        noarkrelbase + 'metadata/hendelsetype/',
        noarkrelbase + 'metadata/journalposttype/',
        noarkrelbase + 'metadata/journalstatus/',
        noarkrelbase + 'metadata/kassasjonsvedtak/',
        noarkrelbase + 'metadata/koordinatsystem/',
        noarkrelbase + 'metadata/klassifikasjonstype/',
        noarkrelbase + 'metadata/korrespondanseparttype/',
        noarkrelbase + 'metadata/land/',
        noarkrelbase + 'metadata/mappetype/',
        noarkrelbase + 'metadata/merknadstype/',
        noarkrelbase + 'metadata/ny-arkivdelstatus/',
        noarkrelbase + 'metadata/ny-arkivstatus/',
        noarkrelbase + 'metadata/ny-avskrivningsmaate/',
        noarkrelbase + 'metadata/ny-dokumentmedium/',
        noarkrelbase + 'metadata/ny-dokumentstatus/',
        noarkrelbase + 'metadata/ny-dokumenttype/',
        noarkrelbase + 'metadata/ny-elektronisksignatursikkerhetsnivaa/',
        noarkrelbase + 'metadata/ny-elektronisksignaturverifisert/',
        noarkrelbase + 'metadata/ny-flytstatus/',
        noarkrelbase + 'metadata/ny-format/',
        noarkrelbase + 'metadata/ny-graderingskode/',
        noarkrelbase + 'metadata/ny-hendelsetype/',
        noarkrelbase + 'metadata/ny-journalposttype/',
        noarkrelbase + 'metadata/ny-journalstatus/',
        noarkrelbase + 'metadata/ny-kassasjonsvedtak/',
        noarkrelbase + 'metadata/ny-koordinatsystem/',
        noarkrelbase + 'metadata/ny-klassifikasjonstype/',
        noarkrelbase + 'metadata/ny-korrespondanseparttype/',
        noarkrelbase + 'metadata/ny-land/',
        noarkrelbase + 'metadata/ny-mappetype/',
        noarkrelbase + 'metadata/ny-merknadstype/',
        noarkrelbase + 'metadata/ny-partrolle/',
        noarkrelbase + 'metadata/ny-postnummer/',
        noarkrelbase + 'metadata/ny-presedensstatus/',
        noarkrelbase + 'metadata/ny-saksstatus/',
        noarkrelbase + 'metadata/ny-skjermingdokument/',
        noarkrelbase + 'metadata/ny-skjermingmetadata/',
        noarkrelbase + 'metadata/ny-slettingstype/',
        noarkrelbase + 'metadata/ny-tilgangskategori/',
        noarkrelbase + 'metadata/ny-tilgangsrestriksjon/',
        noarkrelbase + 'metadata/ny-tilknyttetregistreringsom/',
        noarkrelbase + 'metadata/ny-variantformat/',
        noarkrelbase + 'metadata/ny-virksomhetsspesifikkeMetadata/',
        noarkrelbase + 'metadata/partrolle/',
        noarkrelbase + 'metadata/postnummer/',
        noarkrelbase + 'metadata/presedensstatus/',
        noarkrelbase + 'metadata/saksstatus/',
        noarkrelbase + 'metadata/skjermingdokument/',
        noarkrelbase + 'metadata/skjermingmetadata/',
        noarkrelbase + 'metadata/slettingstype/',
        noarkrelbase + 'metadata/tilgangskategori/',
        noarkrelbase + 'metadata/tilgangsrestriksjon/',
        noarkrelbase + 'metadata/tilknyttetregistreringsom/',
        noarkrelbase + 'metadata/variantformat/',
        noarkrelbase + 'metadata/virksomhetsspesifikkeMetadata/',
        noarkrelbase + 'sakarkiv/',
        noarkrelbase + 'sakarkiv/arkivnotat/',
        noarkrelbase + 'sakarkiv/avskrivning/',
        noarkrelbase + 'sakarkiv/dokumentflyt/',
        noarkrelbase + 'sakarkiv/enkeladresse/',
        noarkrelbase + 'sakarkiv/journalpost/',
        noarkrelbase + 'sakarkiv/kontaktinformasjon/',
        noarkrelbase + 'sakarkiv/ny-arkivnotat/',
        noarkrelbase + 'sakarkiv/ny-avskrivning/',
        noarkrelbase + 'sakarkiv/ny-dokumentflyt/',
        noarkrelbase + 'sakarkiv/ny-enkeladresse/',
        noarkrelbase + 'sakarkiv/ny-journalpost/',
        noarkrelbase + 'sakarkiv/ny-kontaktinformasjon/',
        noarkrelbase + 'sakarkiv/ny-presedens/',
        noarkrelbase + 'sakarkiv/ny-saksmappe/',
        noarkrelbase + 'sakarkiv/presedens/',
        noarkrelbase + 'sakarkiv/saksmappe/',
        noarkrelbase + 'sakarkiv/sekundaerklassifikasjon/',
        noarkrelbase + 'sakarkiv/utvid-til-journalpost/',
        noarkrelbase + 'sakarkiv/utvid-til-saksmappe/',
        'self',
    ]

    # Generated from runtest output, for example like this:
    # curl --silent -L https://gitlab.com/OsloMet-ABI/nikita-noark5-core/-/jobs/417025078/raw |grep 'unable to GET' |sed "s%xfailure: unable to GET http://localhost:8092/noark5v5/%'%" |sed 's%/[-0-9a-z]*[0-9][-0-9a-z]*/%//%' |sed 's%//%/[-0-9a-z]+/%' |sed "s/$/?',/" | sort -u
    # Need some manual editing after generation.
    knownmissingregex = [
        'api/admin/bruker/[-0-9a-z]+/administrativenhet/?',
        'api/admin/bruker/[-0-9a-z]+/ny-administrativenhet/?',
        'api/admin/ny-rettighet/?',
        'api/admin/rettighet/?',
        'api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-arvtager/?',
        'api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-forloeper/?',
        'api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/arkivdel/[-0-9a-z]+/oppbevaringssted/?',
        'api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/oppbevaringssted/?',
        'api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/konverterFil/?',
        'api/arkivstruktur/klasse/[-0-9a-z]+/kryssreferanse/?',
        'api/arkivstruktur/klasse/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/arkivstruktur/klassifikasjonssystem/[-0-9a-z]+/ny-sekundaerklassifikasjon/?',
        'api/arkivstruktur/klassifikasjonssystem/[-0-9a-z]+/sekundaerklassifikasjon/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/avslutt-mappe/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/kryssreferanse/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-klasse/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-klassifikasjonssystem/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/sekundaerklassifikasjon/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/utvid-til-saksmappe/?',
        'api/arkivstruktur/partenhet/[-0-9a-z]+/?',
        'api/arkivstruktur/partperson/[-0-9a-z]+/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/sakarkiv/saksmappe/[-0-9a-z]+/klasse/?',
        'api/sakarkiv/saksmappe/[-0-9a-z]+/ny-klasse/?',
        'api/sakarkiv/saksmappe/[-0-9a-z]+/ny-saksmappe/?',
    ]
    knownwithoutlinksregex = [
        'api/metadata/ny-[a-zA-Z]+/?',
        'api/admin/ny-bruker/?',
        'api/admin/system/?',
        'api/arkivstruktur/ny-arkivskaper',
        'api/arkivstruktur/arkiv/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/arkiv/[-0-9a-z]+/ny-arkivskaper/?',
        'api/arkivstruktur/arkivdel/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-forfatter/?',
        'api/arkivstruktur/dokumentbeskrivelse/[-0-9a-z]+/ny-skjermingmetadata',
        'api/arkivstruktur/dokumentobjekt/[-0-9a-z]+/ny-konvertering/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/arkivdel/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-bygning/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-dnummer/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-enhetsidentifikator/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-foedselsnummer/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-matrikkel/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-plan/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-noekkelord/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/mappe/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/arkivstruktur/klasse/[-0-9a-z]+/ny-noekkelord/?',
        'api/arkivstruktur/klasse/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-noekkelord/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-bygning/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-dnummer/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-enhetsidentifikator/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-foedselsnummer/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-matrikkel/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-oppbevaringssted/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-plan/?',
        'api/arkivstruktur/registrering/[-0-9a-z]+/ny-kryssreferanse/?',
        'api/metadata/virksomhetsspesifikkeMetadata'
    ]
    verbose = False

    def __init__(self):
        baseurl = 'http://localhost:8092/noark5v5/'
        refurl = 'http://n5test.kxml.no/api/'
        parser = argparse.ArgumentParser()
        parser.add_argument("--baseurl", help="(default is %s)" % baseurl)
        parser.add_argument("--reference", help="set baseurl to to demo API site (override --baseurl)",
                            action="store_true")
        parser.add_argument("--verbose", help="enable debug output",
                            action="store_true")
        parser.add_argument("--keep", help="do not delete created objects",
                            action="store_true")
        args = parser.parse_args()
        if args.reference:
            args.baseurl = refurl
        if args.baseurl:
            self.baseurl = args.baseurl
        else:
            self.baseurl = baseurl
        n5core.endpoint.Endpoint.__init__(self, self.baseurl)
        self.created = []
        self.verbose = args.verbose
        self.keeptestdata = args.keep
        self.failures = {}
        self.xfailures = {}
        self.successes = {}
    def success(self, msg):
        if msg not in self.successes:
            self.successes[msg] = 1
            print("success: " + msg)
        return True
    def failure(self, msg):
        if msg not in self.failures:
            self.failures[msg] = 1
            print("failure: " + msg)
        return False
    def verify(self, check, msg):
        if (check):
            return self.success(msg)
        else:
            return self.failure(msg)
    def xsuccess(self, msg):
        if msg not in self.successes:
            self.successes[msg] = 1
            print("xsuccess: " + msg)
        return True
    def xfailure(self, msg):
        if msg not in self.xfailures:
            self.xfailures[msg] = 1
            print("xfailure: " + msg)
        return False
    def xverify(self, check, msg):
        if (check):
            return self.xsuccess(msg)
        else:
            return self.xfailure(msg)

    def isknownmissing(self, url):
        for pattern in self.knownmissingregex:
            fullpattern = self.baseurl + pattern
            if re.match(fullpattern, url) is not None:
                return True
        return False

    def isknownwithoutlinks(self, url):
        for pattern in self.knownwithoutlinksregex:
            fullpattern = self.baseurl + pattern
            if re.match(fullpattern, url) is not None:
                return True
        return False

    def recursiveHateoas(self):
        if self.verbose:
            print("recursively discovering standard URLs from the top")
        relok = {}
        for r in self.knownrels:
            relok[r] = True
        self.urls = []
        self.rels = {}
        urlsleft = ['.']
        urlseen = {}
        while 0 < len(urlsleft):
            url = urlsleft.pop(0)
            if url in urlseen:
                continue
            urlseen[url] = 1
            try:
                (content, res) = self.json_get(url)
                allow = res.getheader('Allow')
                self.success("GET %s worked with code %d"  % (url, res.code))
                self.verify(allow is not None, "GET header should include Allow for %s" % url)
                ctype = res.getheader('Content-Type')

                if -1 != ctype.find('application/json') and \
                   -1 != url.find('.well-known/openid-configuration'):
                    # FIXME add check for openid connect setup
                    if self.verbose:
                        print("no checking for %s" % url)
                    continue

                if (-1 == url.find('/referanseFil/') and
                    self.verify(ctype and 0 == ctype.find('application/vnd.noark5+json'),
                                "MIME type %s should be application/vnd.noark5+json for url %s" % (ctype, url))):
                    #print("C:", content)
                    try:
                        baseref = json.loads(content)
                    except ValueError as e:
                        self.failure('non-JSON content returned for %s' % url)
                        baseref = None
                    #print("J:", baseref)
                    if baseref is None:
                        self.failure("JSON MIME type but no JSON in %s" % url)
                    elif type(baseref) is list:
                        self.failure("found json list in %s" % url)
                    elif '_links' in baseref:
                        for rel in baseref['_links'].keys():
                            l = baseref['_links'][rel]
                            # Detect hrefs with double slashes
                            if 'href' in l \
                               and -1 != l['href'].replace('://', '/').find('//') \
                               and 'self' != rel:
                                self.failure("_links %s with double slashes in %s" % (l['href'], url))
                            # Warn when ny- relations have templated set
                            if '/ny-' in rel and 'templated' in l \
                               and l['templated']:
                                self.xfailure('templated=true relation %s in GET %s' % (rel, url))
                            # Ignore non-standard relations
                            if 'href' in l \
                               and -1 == rel.find("//rel.arkivverket.no/noark5/") \
                               and 'self' != rel:
                                self.xfailure("unofficial relation %s from %s" % (rel, url))
                            elif 'href' in l and \
                                 -1 != rel.find("//rel.arkivverket.no/noark5/"):
                                href = l['href']
                                if 'templated' in l and l['templated']:
                                    href = href.split('{')[0]
                                if href not in urlseen:
                                    urlsleft.append(href)
                                if rel != 'self':
                                    # FIXME figure out if rels should match spec
                                    if rel in relok:
                                        self.success('rel %s is well known' % rel)
                                    elif rel + '/' in relok:
                                        self.success('rel %s is well known (missing trailing slash)' % rel)
                                    else:
                                        self.failure('rel %s in %s should be well known' % (rel, url))
                                    # Only check non-objects for unique relations
                                    if 'systemID' not in baseref \
                                       and not ('_links' in baseref
                                                and 'self' in baseref['_links']
                                                and baseref['_links']['self']
                                                and 'count' not in baseref
                                                and 'results' not in baseref) \
                                       and 'kode' not in baseref \
                                       and '/ny-' not in url \
                                       and rel in self.rels \
                                       and href != self.rels[rel]:
                                        self.failure("unique duplicate rel %s in _links for %s" % (rel, url))
                                    else:
                                        self.rels[rel] = href
                    else:
                        if self.isknownwithoutlinks(url):
                            self.xfailure("missing _links from GET %s" % url)
                        else:
                            self.failure("missing _links from GET %s" % url)
                    if baseref is not None and type(baseref) is not list:
                        for basekey in baseref.keys():
                            if basekey != '_links' and type(baseref[basekey]) is list:
                                for element in baseref[basekey]:
                                    #print(element)
                                    if '_links' in element and len(element['_links']) > 0:
                                        for ref in element['_links'].keys():
                                            href = element['_links'][ref]['href']
                                            if href not in urlseen:
                                                #self.failure("Found new link %s" % href)
                                                urlsleft.append(href)
                self.urls.append(url)
                try:
                    # Check if CORS can work for the URL
                    (ocontent, ores) = self.options(url)
                    allow = []
                    allowstr = ores.getheader('Allow')
                    if allowstr:
                        allow = allowstr.split(',')
                        self.verify(-1 != allow.index('GET'), 'OPTIONS header Allow should include GET for %s' % url)
                    else:
                        self.failure("OPTIONS for URL %s missing Allow header" % url)
                except HTTPError as e:
                    self.failure("OPTIONS failed for URL %s: %s (%s)" % (url, str(e), e.read()))
            except HTTPError as e:
                if self.isknownmissing(url):
                    self.xfailure("unable to GET %s" % url)
                else:
                    self.failure("unable to GET %s" % url)

        for rel in sorted(self.rels.keys()):
            if self.verbose:
                print("mapping %s to %s" % (rel, self.rels[rel]))

    def verifyAuthentication(self):
        """
level 0 authentication.  Verify that a URL requiring login
will contain the WWW-Authenticate header and return HTTP
code 401 before logging in.
"""
        try:
            # FIXME figure out a way avoid hardcoding this URL
            url = "arkivstruktur/arkiv/"
            (content, res) = self.json_get(url)
            self.failure("level 0 accessing %s before login do not ask for basic authentication" % url)
        except HTTPError as e:
            self.xverify(401 == e.code and 'www-authenticate' in e.hdrs,
                        "level 0 API should support support Basic access authentication")

    def testBasis(self):
        """
Test basis requirements for NOARK 5 Core.

"""
        # Verify CORS support,
        # https://en.wikipedia.org/wiki/Cross-origin_resource_sharing
        try:
            (ocontent, ores) = self.options('.')
            self.success("level 0 CORS - HTTP OPTTIONS request worked")
        except HTTPError as e:
            self.failure("level 0 CORS - HTTP OPTTIONS request not working")
        except URLError:
            self.failure("level 0 CORS - unable to connect via HTTP")

        self.verifyAuthentication()

        # Verify ability to produce JSON output
        try:
            (content, res) = self.json_get(".")
            self.success("level 0 JSON - found base")
            contenttype = res.getheader('Content-Type')
            if 0 != contenttype.find('application/vnd.noark5+json'):
                self.failure('level 0 JSON - incorrect content-type for base: %s' % contenttype)
            else:
                self.success('level 0 JSON - correct content-type for base')
                baseref = json.loads(content)
#                print(d)
                if '_links' in baseref:
                    self.success('level 0 JSON - found _links in json response')
                    return baseref
                else:
                    self.failure('level 0 JSON - did not find _links in json response')
        except HTTPError as e:
            self.failure('level 0 JSON - unable to GET JSON content for base.')

        # FIXME Verify authentication, not sure how
        return None

    def parselinks(self,links):
        rels = {}
        for rel in links.keys():
            if 'href' in links[rel]:
                rels[rel] = links[rel]['href']
        return rels

    def createEntity(self, name, rel, rels, data, failureexpected=False):
        if self.verbose:
            print("trying to create %s" % name)
        if failureexpected:
            failure=self.xfailure
            verify=self.xverify
        else:
            failure=self.failure
            verify=self.verify
        if rel not in rels:
            failure("unable to create a new %s, no %s entry discovered even if logged in" % (name, rel))
            return
        url = rels[rel]
        try:
            (gc, gres) = self.json_get(url)
            default = json.loads(gc)
            print("GET %s returned %s" % (url, default))
            # using default values in POST
            for k in default.keys():
                if not k == '_links' and k not in data:
                    data[k] = default[k]
            self.success("GET %s worked with code %d"  % (url, gres.code))
            etag = gres.getheader('ETag')
            self.verify(etag is None, "no ETag from GET on %s" % url)
            try:
                # Verify OPTIONS announce POST support
                (ocontent, ores) = self.options(url)
                allow = []
                allowstr = ores.getheader('Allow')
                if allowstr:
                    allow = allowstr.split(',')
                    verify('POST' in allow, 'OPTIONS header Allow should include POST for %s' % url)
                    verify('GET' in allow, 'OPTIONS header Allow should include GET for %s' % url)
                else:
                    failure("OPTIONS for URL %s missing Allow header" % url)
            except HTTPError as e:
                failure('unable to OPTIONS %s: %s' % (url, e.read()))
        except HTTPError as e:
            failure('unable to GET %s: %s' % (url, e.read()))
        print("POST %s: %s" % (url, data))
        try:
            (c, res) = self.json_post(url, data)
        except HTTPError as e:
            failure("POST %s failed: %s" % (url, e.read()))
            raise
        except TypeError as e:
            failure("POST %s unable to parse JSON response: %s" % (url, str(e)))
            raise
        info = json.loads(c)
        verify('_links' in info and 'self' in info['_links']
               and info['_links']['self'], "created %s" % name)
        verify(201 == res.code, "verify %s creation return HTTP code %s is 201" % (name, res.code))
        linkrefs = self.parselinks(info['_links'])
        verify('self' in linkrefs, "_links in response from %s creation should include 'self' reference" % name)
        if 'self' in linkrefs:
            selfurl = self.parselinks(info['_links'])['self']
            self.created.append(selfurl)
            # Make sure the 'self' url is GET-able
            try:
                extrainfo = self.json_get(selfurl)
                self.success("able to GET self url %s" % selfurl)
            except HTTPError as e:
                failure("unable to GET self url %s" % selfurl)
        for k in data.keys():
            if verify(k in info,
                           "POST %s respons should have key %s" % (url, k)):
                if verify(type(data[k]) == type(info[k]),
                          'type of attribute %s matches for sent (%s) and received (%s) JSON' % (
                              k, type(data[k]), type(info[k]),
                          )):
                    if list is type(data[k]):
                        for v in data[k]:
                            verify(data[k][v] == info[k][v],
                                        "POST %s respons list member %s should match %s" %
                                        (url, k, v, data[k][v]))
                    elif dict is type(data[k]):
                        if self.verbose:
                            print("data[%s]: %s" % (k, data[k]))
                            print("info[%s]: %s" % (k, info[k]))
                        for v in data[k].keys():
                            print("checking %s key %s" % (k, v))
                            verify(k in data and k in info
                                   and v in data[k] and v in info[k]
                                   and data[k][v] == info[k][v],
                                        "POST %s respons dict %s key %s respons %s should match %s" %
                                        (url, k, v, info[k].get(v), data[k][v]))
                    else:
                        verify(info[k] == data[k],
                                    "POST %s response for '%s' ('%s') should match '%s'" % (url, k, info[k], data[k]))
        return info

    def deleteCreated(self):
        for entityurl in self.created[::-1]:
            try:
                (infostr, res) = self.json_get(entityurl)
                info = json.loads(infostr)
                # FIXME Should DELETE  return ETag?
                etag = res.getheader('ETag')
                self.verify(etag is not None,
                            "DELETE endpoint return ETag on %s" % entityurl)
                (dcontent, dres) = self.delete(entityurl, etag=etag)
                self.success("able to DELETE %s" % entityurl)
                self.verify(204 == dres.code, "status code=%d (should be 204) for DELETE %s" % (dres.code, entityurl))
            except HTTPError as e:
                self.failure("unable to DELETE %s: %s" % (entityurl, e.read()))


    def testAllAttributes(self):
        someuser = "Bill Watterson"
        timestamp = "1958-07-05T12:00:00"
        someid = "BillWattersonId"
        testdata = {
            "arkiv" : {
                "selfrel" : None,
                "rel" : noarkrelbase + 'arkivstruktur/ny-arkiv/',
                "required" : {
                    "tittel"               : "arkiv-tittel",
                },
                "readonly" : {
                    "systemID"             : None,
                    "oppdatertDato"        : timestamp,
                    "oppdatertAv"          : someuser,
                    "opprettetDato"        : timestamp,
                    "opprettetAv"          : someuser,
                },
                "optional" : {
                    "beskrivelse"          : "arkiv",
                    "arkivstatus"          : "arkivstatus",
                    "dokumentmedium"       : "Elektronisk arkiv",
                    "avsluttetDato"        : timestamp,
                    "avsluttetAv"          : someuser,
                    #"referanseOppdatertAv" : someid,
                    #"referanseOpprettetAv" : someid,
                    #"referanseAvsluttetAv" : someid,
                }
            }
        }
        for type in testdata.keys():
            rel = testdata[type]["rel"]
            # FIXME get this code working
            fondinfo = self.createEntity(type, rel, self.rels, data)
            linkrefs = self.parselinks(fondinfo['_links'])
            if 'self' in linkrefs:
                selfurl = self.parselinks(fondinfo['_links'])['self']
                self.delete(selfurl)

            if fondinfo is None:
                return
            return fondinfo

    def modifyAllCreated(self):
        for url in self.created:
            try:
                (infostr, res) = self.json_get(url)
                info = json.loads(infostr)
                etag = res.getheader('ETag')
                self.verify(etag is not None,
                            "PUT endpoint return ETag on %s" % url)
                for key in info.copy().keys():
                    keytype = type(info[key])
                    if list == keytype:
                        # list members are modified using other
                        # accessors.
                        print("removing key %s: %s" % (key, info[key]))
                        info.pop(key, None)
                modkey = None
                for keycandidate in (
                        'arkivertAv',
                        'arkivskaperNavn',
                        'bygningsnummer',
                        'dNummer',
                        'foedselsnummer',
                        'forfatter',
                        'oppbevaringssted',
                        'kommunenummer',
                        'konverteringskommentar',
                        'merknadstekst',
                        'mimeType',
                        'navn',
                        'noekkelord',
                        'organisasjonsnummer',
                        'tittel',
                        'x'
                ):
                    if keycandidate in info:
                        modkey = keycandidate
                if modkey:
                    if int == type(info[modkey]) or float == type(info[modkey]):
                        info[modkey] = info[modkey] + 1
                    else:
                        info[modkey] = info[modkey] + ' modified'
                else:
                    self.xfailure('unable to find anything to modify among %s' % info.keys())
                    print(info)
                infostr = json.dumps(info)
                putinfo, putres = self.put(url, infostr,
                                   'application/vnd.noark5+json',
                                   etag=etag)
                #print(putinfo)
                self.success("able to modify %s" % url)
                self.verify(200 == putres.code, "status code=%d (should be 200) for PUT %s" % (putres.code, url))
            except HTTPError as e:
                if self.isknownmissing(url):
                    self.xfailure("unable to modify %s: %s (%s)" % (url, str(e), e.read()))
                else:
                    self.failure("unable to modify %s: %s (%s)" % (url, str(e), e.read()))

    def testDateFormats(self):
        """
Check if the API can handle all valid date and datetime formats.
The spec state that the API should handle all formats listed in
https://www.w3.org/TR/xmlschema11-2/, with timezone required.

Also, should 'date' fields accept values with time of day in them,
or should it be rejected?

"""
        rel = noarkrelbase + 'arkivstruktur/ny-registrering/'
        name = 'record'
        field = "arkivertDato"

        # FIXME Need to pick a object with 'date' and try to create it with variations
        # Perhaps journalpost with mottattDato?
        datemust = []
        datecould = []

        datetimemust = [
            '1997-07-16T19:20+01:00', # From NOTE-datetime
            '1997-07-16T19:20:30+01:00', # From NOTE-datetime
            '1997-07-16T19:20:30.45+01:00', # From NOTE-datetime

            '2012-10-10T15:00:00Z', # From example extraction data sets
            '2014-11-22T15:15:02.956+01:00', # From example extraction data sets
        ]

        datetimecould = [
            '1997-07-16Z', # From NOTE-datetime accepted by XMLSChema date not datetime

            '1865-02-13T00:00:00Z', # From example extraction data sets
        ]
        datetimereject = [
            '1997', # From NOTE-datetime, not accepted by XMLSChema date nor datetime
            '1997-07', # From NOTE-datetime, not accepted by XMLSChema date nor datetime
            '1997-07-16', # From NOTE-datetime accepted by XMLSChema date not datetime
        ]

        for timevalues, level in [(datetimemust, self.failure), (datetimecould, self.xfailure)]:
            for timevalue in timevalues:
                try:
                    data = {
                        field : timevalue,
                    }
                    info = self.createEntity(name, rel, self.rels, data, failureexpected=True)
                    if info:
                        self.success("able to create record with %s='%s'" % (field, timevalue))
                    else:
                        level("unable to create record with %s='%s'" % (field, timevalue))
                except HTTPError as e:
                    level("unable to create record with %s='%s'" % (field, timevalue))

    def testNewDocument(self):
        now = utcnowtz().replace(microsecond=0) \
                        .isoformat() \
                        .replace('+00:00', 'Z')
        if not self.gotlogin:
            self.failure("not logged in, unable to test creation")
            return

        createrecordcreatorrel = noarkrelbase + 'arkivstruktur/ny-arkivskaper/'
        recordcreatordata = {
            'arkivskaperID' : u'123456789',
            'arkivskaperNavn': u'Mr. arkivskaper',
            #'beskrivelse': 'fin fyr',
        }
        recordcreatorinfo = self.createEntity('recordcreator',
                                            createrecordcreatorrel, self.rels,
                                            recordcreatordata)
        if recordcreatorinfo is None:
            return

        createfondsrel = noarkrelbase + 'arkivstruktur/ny-arkiv/'
        fondsdata = {
            "tittel"          : u"Title of the test fonds created %s" % now,
#            "beskrivelse"     : "Description of the test fonds",
#            "dokumentmedium"  : "Elektronisk arkiv",
        }
        fondinfo = self.createEntity('fonds', createfondsrel,
                                     self.parselinks(recordcreatorinfo['_links']),
                                     fondsdata)
        if fondinfo is None:
            return

        seriesdata = {
            "tittel"          : u"Title of the test series created %s" % now,
#            "beskrivelse"     : "Description of the test series",
#            "dokumentmedium"  : "Elektronisk arkiv",
#            "arkivdelstatus" : { "kode": u"O" },
            "gradering": {
                "graderingskode": {
                    "kode":"SH",
                    "kodenavn":"Strengt hemmelig (sikkerhetsgrad)"
                },
                "graderingsdato": "1865-02-13T00:00:00+01:00",
                "gradertAv": "PST",
                "nedgraderingsdato": "2070-02-13T00:00:00-01:00",
                "nedgradertAv": "PST"
            },
        }
        createseriesrel = noarkrelbase + 'arkivstruktur/ny-arkivdel/'
        serieinfo = self.createEntity('serie', createseriesrel,
                                      self.parselinks(fondinfo['_links']),
                                      seriesdata)

        try:
            seriesdata = {
                "tittel"          : u"Title of the deleted test series created %s" % now,
                "sletting": {
                    "slettingstype": {
                        "kode": "SP",
                        "kodenavn": "Sletting av produksjonsformat"
                    },
                    "slettetDato": "1880-10-10T00:00:00+01:00",
                    "slettetAv": "Vaktmester",
                    #"referanseSlettetAv": someid
                },
            }
            delserieinfo = self.createEntity('serie', createseriesrel,
                                          self.parselinks(fondinfo['_links']),
                                          seriesdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        classificationsystemdata = {
            'tittel': u'Title of the test classification system created %s' % now,
#            'klassifikasjonstype' : { 'kode' : 'FH', },
        }
        createclassificationsystemrel = \
            noarkrelbase + 'arkivstruktur/ny-klassifikasjonssystem/'
        classificationsysteminfo = \
            self.createEntity('classificationsystem',
                              createclassificationsystemrel,
                              self.parselinks(serieinfo['_links']),
                              classificationsystemdata)

        classdata = {
            'klasseID' : u'Test class created %s' % now,
            'tittel': u'Title of the test class created %s' % now,
        }
        createclassrel = \
            noarkrelbase + 'arkivstruktur/ny-klasse/'
        classinfo = \
            self.createEntity('class', createclassrel,
                              self.parselinks(classificationsysteminfo['_links']),
                              classdata)

        # Test adding keyword to class
        createkeywordrel = nikitarelbase + 'ny-noekkelord/'
        for keyword in (u'old', u'facinating'):
            keyworddata = {
                'noekkelord': keyword,
            }
            try:
                keywordinfo = \
                    self.createEntity('keyword', createkeywordrel,
                                      self.parselinks(classinfo['_links']),
                                      keyworddata, failureexpected=True)
            except HTTPError as e:
                pass

        subclassdata = {
            'klasseID' : u'Test subclass created %s' % now,
            'tittel': u'Title of the test subclass created %s' % now,
        }
        subclassinfo = \
            self.createEntity('subclass', createclassrel,
                              self.parselinks(classinfo['_links']),
                              subclassdata)

        subclassfiledata = {
            'tittel' : u"Title of the sub-class test file created %s" % now,
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        subclassfileinfo = \
            self.createEntity('file', createfilerel,
                              self.parselinks(subclassinfo['_links']),
                              subclassfiledata)

        # Test file with UTF-8 character longer than 3 bytes (problem
        # with some MySQL backend engines.
        u8filedata = {
            "tittel"      : u"Fly high, try the 🛫 created %s" % now,
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        try:
            u8fileinfo = self.createEntity('file', createfilerel,
                                           self.parselinks(serieinfo['_links']),
                                           u8filedata, failureexpected=True)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        filedata = {
#            "mappeID"            : "2017/01",
#            "offentligTittel"    : "Public title of the test file created %s" % now,
            "tittel"             : u"Title of the test file created %s" % now,
#            "beskrivelse"        : "Description of the test file",
#            "dokumentmedium"     : "Elektronisk arkiv",
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        fileinfo = self.createEntity('file', createfilerel,
                                     self.parselinks(serieinfo['_links']),
                                     filedata)

        self.xverify('mappeID' in fileinfo, "new file should have mappeID added automatically")

        for (c, f) in [
                ('enhet', u'navn'),
                ('person', u'navn'),
        ]:
            partrel = noarkrelbase + 'arkivstruktur/ny-part%s/' % c
            for code in (u'KLI', u'PAA', u'FORM', u'ADV'):
                partdata = {
                    'partRolle' : {
                        'kode' : code
                    },
                    f : u'Eksempel %s' % code,
                }
                try:
                    partinfo = \
                        self.createEntity('part %s' % c,
                                          partrel,
                                          self.parselinks(fileinfo['_links']),
                                          partdata)
                except HTTPError as e:
                    pass
        # Test adding comment to file
        commentdata = {
            'merknadstekst': u'Title of file comment created %s' % now,
        }
        createcommentrel = noarkrelbase + 'arkivstruktur/ny-merknad/'
        try:
            commentinfo = self.createEntity('comment', createcommentrel,
                                            self.parselinks(fileinfo['_links']),
                                            commentdata)
        except HTTPError as e:
            pass

        # Test adding keyword to file
        createkeywordrel = nikitarelbase + 'ny-noekkelord/'
        for keyword in (u'new', u'interesting'):
            keyworddata = {
                'noekkelord': keyword,
            }
            try:
                keywordinfo = \
                    self.createEntity('keyword', createkeywordrel,
                                      self.parselinks(fileinfo['_links']),
                                      keyworddata, failureexpected=True)
            except HTTPError as e:
                pass

        # Test adding location to file
        createlocationrel = nikitarelbase + 'ny-oppbevaringssted/'
        for location in (u'hjemme', u'bomberommet'):
            locationdata = {
                'oppbevaringssted': location,
            }
            try:
                locationinfo = \
                    self.createEntity('location', createlocationrel,
                                      self.parselinks(fileinfo['_links']),
                                      locationdata, failureexpected=True)
            except HTTPError as e:
                pass

        # Test adding nasjonal identifiers to file
        nitestdata = [
                ('bygning', {
                    'bygningsnummer': 1,
                    'endringsloepenummer': 2,
                }),
                ('dnummer', {
                    'dNummer': u'01010101011',
                }),
                ('enhetsidentifikator', {
                    'organisasjonsnummer': u'02020202022',
                }),
                ('foedselsnummer', {
                    'foedselsnummer': u'03030303033'
                }),
                ('matrikkel', {
                    'kommunenummer' : u'0101',
                    'gaardsnummer' : 0,
                    'bruksnummer' : 0,
                    'festenummer' : 1,
                    'seksjonsnummer' : 1,
                }),
                ('plan', {
                    'kommunenummer': u'0101',
                    'fylkesnummer': u'01',
                    'landkode': {
                        'kode': u'NO',
                        'kodenavn': u'Norge',
                    },
                    'planidentifikasjon': u'050505',
                }),
                ('posisjon', {
                    'koordinatsystem': {
                        'kode': u'EPSG:4326',
                        'kodenavn': u'WGS84',
                    },
                    'x': 1.01,
                    'y': 2.02,
                    'z': 3.03,
                }),
        ]
        for (idtype, data) in nitestdata:
            rel = noarkrelbase + 'arkivstruktur/ny-%s/' % idtype
            try:
                info = self.createEntity('national identifier %s' % idtype,
                                         rel,
                                         self.parselinks(fileinfo['_links']),
                                         data)
            # We can try the next even if the previous one failed with
            # one of these.  They are already reported by
            # createEntity, so no need to call failed().
            except TypeError as e:
                pass
            except HTTPError as e:
                pass
        recorddata = {
        }
        createrecordrel = noarkrelbase + 'arkivstruktur/ny-registrering/'
        recordinfo = self.createEntity('record', createrecordrel,
                                       self.parselinks(fileinfo['_links']),
                                       recorddata)

        # Test adding keyword to record
        createkeywordrel = nikitarelbase + 'ny-noekkelord/'
        for keyword in (u'old', u'facinating'):
            keyworddata = {
                'noekkelord': keyword,
            }
            try:
                keywordinfo = \
                    self.createEntity('keyword', createkeywordrel,
                                      self.parselinks(recordinfo['_links']),
                                      keyworddata, failureexpected=True)
            except HTTPError as e:
                pass

        # Test adding nasjonal identifiers to record
        for (idtype, data) in nitestdata:
            rel = noarkrelbase + 'arkivstruktur/ny-%s/' % idtype
            try:
                info = self.createEntity('national identifier %s' % idtype,
                                         rel,
                                         self.parselinks(recordinfo['_links']),
                                         data)
            # We can try the next even if the previous one failed with
            # one of these.  They are already reported by
            # createEntity, so no need to call xfailed().
            except TypeError as e:
                pass
            except HTTPError as e:
                pass

        casefiledata = {
#            "mappeID"            : "2017/1",
#            "offentligTittel"    : "Public title of the test case file created %s" % now,
            "tittel"             : u"Title of the test case file created %s" % now,
#            "beskrivelse"        : "Description of the test file",
#            "dokumentmedium"     : "Elektronisk arkiv",
#            "saksdato"           : "2016-10-04",
#            "administrativEnhet" : "The administrative unit",
#            "saksansvarlig"      : "Joe the case handler",
#            "saksstatus"         : "Opprettet",
        }
        createcasefilerel = noarkrelbase + 'sakarkiv/ny-saksmappe/'
        casefileinfo = self.createEntity('casefile', createcasefilerel,
                                         self.parselinks(serieinfo['_links']),
                                         casefiledata)
        self.verify('mappeID' in casefileinfo, "new case file should have mappeID added automatically")
        casefileurl = self.parselinks(casefileinfo['_links'])['self']

        try:
            precedencedata = {
                'presedensDato': now,
                'tittel': u'Because that is the way it is',
                'rettskildefaktor': u'The Boss',
            }
            createprecedencerel = noarkrelbase + 'sakarkiv/ny-presedens/'
            precedenceinfo = self.createEntity(
                'precedence',
                createprecedencerel,
                self.parselinks(casefileinfo['_links']),
                precedencedata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        for (c, f) in [
                ('enhet', u'navn'),
                ('person', u'navn'),
        ]:
            partrel = noarkrelbase + 'arkivstruktur/ny-part%s/' % c
            for code in (u'KLI', u'PAA', u'FORM', u'ADV'):
                partdata = {
                    'partRolle' : {
                        'kode' : code
                    },
                    f : u'Eksempel %s' % code,
                }
                try:
                    partinfo = \
                        self.createEntity('part %s' % c,
                                          partrel,
                                          self.parselinks(casefileinfo['_links']),
                                          partdata)
                except HTTPError as e:
                    pass
        archivenotedata = {
            'tittel': u'test av arkivnotat',
        }
        archivenoterel = noarkrelbase + 'sakarkiv/ny-arkivnotat/'
        archivenoteinfo = self.createEntity('archivenote', archivenoterel,
                                            self.parselinks(casefileinfo['_links']),
                                            archivenotedata)
        try:
            docflowdata = {
                'flytTil': u'Sjefen',
            }
            createdocflowrel = noarkrelbase + 'sakarkiv/ny-dokumentflyt/'
            docflowinfo = self.createEntity('document flow',
                                            createdocflowrel,
                                            self.parselinks(archivenoteinfo['_links']),
                                            docflowdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        journalentrydata = {
            'tittel' : u'test',
            # Override non-utf-8 values from nikita to keep runtest
            # working on gitlab.
            u'journalposttype': { u'kode': u'I' },
            u'journalstatus': { u'kode': u'J' },
        }
        createjournalentryrel = noarkrelbase + 'sakarkiv/ny-journalpost/'
        journalentryinfo = self.createEntity('journalentry',
                                             createjournalentryrel,
                                             self.parselinks(casefileinfo['_links']),
                                             journalentrydata)

        journalentrydata = {
            'tittel' : u'test reply',
            u'journalposttype': { u'kode': u'U' },
            u'journalstatus': { u'kode': u'J' },
        }
        ujournalentryinfo = self.createEntity('journalentry',
                                             createjournalentryrel,
                                             self.parselinks(casefileinfo['_links']),
                                             journalentrydata)

        signoffdata = {
            'avskrivningsmaate' : {
                'kode' : 'BU',
            },
            'referanseAvskrivesAvJournalpost': ujournalentryinfo['systemID'],
        }
        createsignoffrel = noarkrelbase + 'sakarkiv/ny-avskrivning/'
        try:
            signoffinfo = \
                self.createEntity('sign off',
                                  createsignoffrel,
                                  self.parselinks(journalentryinfo['_links']),
                                  signoffdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        for (c, f) in [('enhet', u'navn'),
                       ('person', u'navn'),
                       # ('intern', 'administrativenhet') # FIXME not working yet
        ]:
            corrpartrel = noarkrelbase + 'arkivstruktur/ny-korrespondansepart%s/' % c
            for code in ('EA', 'EM', 'EK', 'GM', 'IA', 'IM', 'IK'):
                corrdata = {
                    'korrespondanseparttype' : {
                        'kode' : code
                    },
                    f : u'Eksempel %s' % code,
                }
                corrinfo = self.createEntity('correspondance part %s' % c,
                                             corrpartrel,
                                             self.parselinks(journalentryinfo['_links']),
                                             corrdata)
        docdescdata = {
#            "dokumenttype"    : "type dokument",
#            "dokumentstatus"  : "status of document",
            "tittel"          : u"Title of the test document description created %s" % now,
#            "tilknyttetRegistreringSom" : "Associated with record as"
        }
        createdocdescrel = noarkrelbase + 'arkivstruktur/ny-dokumentbeskrivelse/'
        docdescinfo = self.createEntity('document description',
                                        createdocdescrel,
                                        self.parselinks(recordinfo['_links']),
                                        docdescdata)
        try:
            docdescdata = {
                "tittel"          : u"Title of deleted test document description created %s" % now,
                "sletting": {
                    "slettingstype": {
                        "kode": "SP",
                        "kodenavn": "Sletting av produksjonsformat"
                    },
                    "slettetDato": "1880-10-10T00:00:00+01:00",
                    "slettetAv": "Vaktmester",
                    #"referanseSlettetAv": someid
                },
            }
            deldocdescinfo = self.createEntity('document description',
                                            createdocdescrel,
                                            self.parselinks(recordinfo['_links']),
                                            docdescdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        try:
            scrndocdescdata = {
                'tittel'          : u'Title of screened test document description created %s' % now,
                'skjerming': {
                    'tilgangsrestriksjon': {
                        'kode': 'P',
                        'kodenavn': 'Personalsaker'
                    },
                    'skjermingshjemmel': 'Unntatt etter Offentleglova',
                    'skjermingDokument': { 'kode': 'H', 'kodenavn': 'Skjerming av hele dokumentet' },
                    'skjermingsvarighet': 60,
                    'skjermingOpphoererDato': '1942-07-25T12:00:00Z',
                }
            }
            scrndocdescinfo = self.createEntity('document description',
                                                createdocdescrel,
                                                self.parselinks(recordinfo['_links']),
                                                scrndocdescdata)
            scrmetarel = nikitarelbase + 'ny-skjermingmetadata/'
            for scrmetadata in (
                    { 'kode': 'NA', 'kodenavn': 'Skjerming navn avsender' },
                    { 'kode': 'TKL', 'kodenavn': 'Skjerming tittel klasse' },
            ):
                scrnmetainfo = \
                    self.createEntity('skjermingMetadata',
                                      scrmetarel,
                                      self.parselinks(scrndocdescinfo['_links']),
                                      scrmetadata, failureexpected=True)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        # Try metadata with same code 'B' for different types. Trigger
        # bug in Nikita where the wrong metadata type is used to look
        # up values.
        # https://gitlab.com/OsloMet-ABI/nikita-noark5-core/-/issues/184
        try:
            docdescdata = {
                'tittel': u'Title of the test document description created %s' % now,
                'tilknyttetRegistreringSom': {
                    'kode': u'H',
                    'kodenavn': u'Hoveddokument'
                },
                'dokumentstatus': {
                    'kode': u'B',
                    'kodenavn': u'Dokumentet er under redigering'
                },
                'dokumenttype': {
                    'kode': u'B',
                    'kodenavn': u'Brev'
                },
            }
            mddocdescinfo = \
                self.createEntity('document description',
                                  createdocdescrel,
                                  self.parselinks(recordinfo['_links']),
                                  docdescdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        # Attach author to first document description
        authordata = {
            'forfatter': u'Henrik Ibsen',
        }
        createauthorrel = nikitarelbase + 'ny-forfatter/'
        try:
            authorinfo = \
                self.createEntity('author', createauthorrel,
                                  self.parselinks(docdescinfo['_links']),
                                  authordata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        xmldata = "<?xml version=\"1.0\" encoding=\"UTF-8\"?><xml></xml>\n".encode('utf-8')
        hashalg = u'SHA-256'
        hasher = sha256()
        hasher.update(xmldata)
        hash = hasher.hexdigest()

        docobjdata = {
#            "versjonsnummer"  : 1,
#            "variantformat"   : "Arkivformat",
            "format"          : { 'kode': "fmt/101" },
#            "formatDetaljer"  : "home made XML",
            "sjekksum"          : str(hash),
            "sjekksumAlgoritme" : str(hashalg),
            "filstoerrelse"     : len(xmldata),
#            "mimeType"       : "application/xml",
        }
        createdocobjrel = noarkrelbase + 'arkivstruktur/ny-dokumentobjekt/'
        docobjinfo = self.createEntity('document object', createdocobjrel,
                                       self.parselinks(docdescinfo['_links']),
                                       docobjdata)

        # FIXME try to upload a file, for example an xml file and large
        # chunked file.
        reffilerel = noarkrelbase + 'arkivstruktur/fil/'
        self.verify(reffilerel in self.parselinks(docobjinfo['_links']),
                    "_links in response from %s rel should include '%s' rel" % (createdocobjrel, reffilerel))
        rels = self.parselinks(docobjinfo['_links'])
        url = rels[reffilerel]
        try:
            (c, res) = self.post(url, xmldata, 'application/xml')
            # The spec is not clear on what is returned from file upload
            #self.verify(c == '', "POST %s return nothing" % url)
            self.verify(201 == res.code, "verify file upload HTTP code %s is 201" % (res.code))
        except HTTPError as e:
            print("POST %s failed: %s (%s)" % (url, str(e), e.read()))

        # Verify the pointer to the file to download
        (infostr, res) = self.json_get(rels['self'])
        docobjinfo2 = json.loads(infostr)
        if (self.verify(reffilerel in self.parselinks(docobjinfo2['_links']),
                        "_links in response from %s rel should include '%s' rel" % (createdocobjrel, reffilerel))):
            self.verify('referanseDokumentfil' not in docobjinfo2,
                        "referanseDokumentfil should not exist")

        try:
            headers = { 'Accept' : 'application/xml' }
            (c, res) = self._get(url)
            self.verify(c == xmldata,
                        "downloaded file should match uploaded file ('%s' != '%s') (%s %s)" % (xmldata, c, type(xmldata), type(c)))
            ctype = res.getheader('Content-Type')
            self.verify(ctype and 0 == ctype.find('application/xml'),
                        "MIME type %s should be application/xml for url %s" %
                        (ctype, url))
        except HTTPError as e:
            self.failure("downloading %s failed: %s (%s)" % (url, str(e), e.read()))
        # Attach conversion to document object
        convdata = {
            "konvertertFraFormat": { u'kode': u"x-fmt/111" },
            "konvertertTilFormat": { u'kode': u"fmt/101" },
            "konverteringsverktoey": u"runtime tester",
            "konverteringskommentar": u"tullekonvertering",
        }
        createconvrel = noarkrelbase + 'arkivstruktur/ny-konvertering/'
        try:
            convinfo = self.createEntity('conversion', createconvrel,
                                         self.parselinks(docobjinfo['_links']),
                                         convdata)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        # Test simple VSM entry, first with a name currently not
        # listed in the vsm directory.
        filedata = {
            u'tittel' : u"Title of the vsm test file created %s" % now,
            'virksomhetsspesifikkeMetadata': {
                u'n5t-v1:bogus': u'42',
            }
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        try:
            fileinfo = self.createEntity('file', createfilerel,
                                         self.parselinks(serieinfo['_links']),
                                         filedata, failureexpected=True)
        except HTTPError as e:
            pass # Problem already reported by createEntity, keep going

        # Next, ensure we use an existing VSM name or register a new
        # one.
        metadatarel = noarkrelbase + 'metadata/'
        vsmrel = "%smetadata/virksomhetsspesifikkeMetadata/" \
            % self.relbaseurl
        createvsmrel = "%smetadata/ny-virksomhetsspesifikkeMetadata/" \
            % self.relbaseurl
        url = self.findRelation(metadatarel)
        (entry, res) = self.json_get(url)
        metadatalist = json.loads(entry)
        links = self.parselinks(metadatalist['_links'])

        try:
            (entry, res) = self.json_get(links[vsmrel])
            vsmlist = json.loads(entry)
        except HTTPError as e:
            print("GET %s failed: %s (%s)" % (url, str(e), e.read()))
            raise
        self.vsmkey = None
        if 0 < vsmlist['count']:
            # Pick and use the first with type 'string'
            for v in vsmlist['results']:
                if 'string' == v['type']:
                    self.vsmkey = v['navn']
                    break
        if not self.vsmkey: # Create one to use during testing
            self.vsmkey = 'n5t-v1:real'
            vsmdata = {
                u'navn' : self.vsmkey,
                u'type' : u'string',
#                'beskrivelse' : '',
#                'kilde' : '',
#                'utdatert' : False,
            }
            try:
                vsmmetainfo = self.createEntity('virksomhetsspesifikkeMetadata',
                                                createvsmrel, links, vsmdata)
            except HTTPError as e:
                pass # Problem already reported by createEntity, keep going


        # Create one with well known vsm value too
        filedata = {
            u'tittel' : u"Title of the vsm test file created %s" % now,
            u'virksomhetsspesifikkeMetadata': {
                self.vsmkey : u'one for the team',
            }
        }
        createfilerel = noarkrelbase + 'arkivstruktur/ny-mappe/'
        fileinfo = self.createEntity('file', createfilerel,
                                     self.parselinks(serieinfo['_links']),
                                     filedata)


    def testMetadata(self):
        # First, check if all known metadata relations are listed under metadat.
        knownmetarels = []
        knownmetadata = []
        for rel in self.knownrels:
            r = re.match(r'.*/metadata/(\w+)/?', rel)
            if r:
                knownmetarels.append(rel)
                if -1 == rel.find('/ny-'):
                    knownmetadata.append(r.group(1))

        metadatarel = noarkrelbase + 'metadata/'
        url = self.findRelation(metadatarel)

        if not url:
            self.failure("unable to find %s" % metadatarel)
            return

        (entry, res) = self.json_get(url)
        metadatalist = json.loads(entry)
        for rel in metadatalist['_links'].keys():
            if rel in knownmetarels:
                knownmetarels.remove(rel)
            else:
                self.xfailure("unofficial relation %s from %s" % (rel, url))
        if knownmetarels:
            self.failure("metadata relation keys %s not listed under %s"
                          % (knownmetarels, url))
        else:
            self.success("all known metadata relation keys listed under %s" % url)

        # Make sure 'Journalført' is listed as a journalstatus entry.
        # Looking for this one to detect mojobake with æøå in entries.
        kodenavn = u'Journalført'
        journalstatusrel = noarkrelbase + 'metadata/journalstatus/'
        url = self.findRelation(journalstatusrel)
        (entry, res) = self.json_get(url)
        j = json.loads(entry)
        found = False
        for s in j['results']:
            if kodenavn == s['kodenavn']:
                found = True
                break
        self.verify(found, "looking for UTF-8 metadata journalstatus value")

        if not self.gotlogin:
            self.failure("not logged in, unable to test creation")
            return

        # FIXME make test able to run again with --keep (normally the
        # created value will be removed).
        metadatavalue = {
            'kode': u'XYZ',
            'kodenavn': u'ZYX',
        }
        links = self.parselinks(metadatalist['_links'])
        for metadata in knownmetadata:
            # VSM entpoint is special, do not treat it as a normal metadata type
            if 'virksomhetsspesifikkeMetadata' == metadata:
                continue
            rel = self.relbaseurl + 'metadata/ny-%s/' % metadata
            try:
                info = self.createEntity(metadata, rel, links, metadatavalue)
            except HTTPError as e:
                # Message already printed in createEntity()
                pass
            except TypeError as e:
                self.failure("unable to create %s" % metadata)

    def testOdataSearch(self):
        """Try to find and count the stuff inserted by testNewDocument()
"""
        searches = ( # relkey path - filter string - result count
            ('arkivstruktur/dokumentobjekt/',
             "sjekksumAlgoritme eq 'SHA-256'", 1),

            ('arkivstruktur/dokumentbeskrivelse/',
             "opprettetAv eq 'admin@example.com'", 1),

            ('arkivstruktur/dokumentbeskrivelse/',
             "dokumentstatus/kode eq 'B'", 1),

            ('arkivstruktur/dokumentbeskrivelse/',
             "dokumentstatus/kode EQ 'B'", 1),

            ('arkivstruktur/registrering/',
             "contains(tittel, 'test')", 1),

            ('arkivstruktur/mappe/',
             "contains(part/navn, 'Eksempel')", 1),

            ('arkivstruktur/mappe/',
             "part/partRolle/kode eq 'ADV'", 1),

            ('arkivstruktur/mappe/',
             "contains(tittel, 'file') AND dokumentmedium/kode eq null and saksaar ne null", 1),

            # FIXME Figure out notation to search for this
            ('arkivstruktur/mappe/',
             "enhetsidentifikator/organisasjonsnummer eq '02020202022'", -1),

            ('arkivstruktur/mappe/',
             "nasjonalidentifikator/organisasjonsnummer eq '02020202022'", -1),

            ('arkivstruktur/mappe/',
             "nasjonalidentifikator/foedselsnummer eq '03030303033'", -1),

            ('arkivstruktur/mappe/',
             "personidentifikator/foedselsnummer eq '03030303033'", -1),

            ('arkivstruktur/mappe/',
             "nasjonalidentifikator/foedselsnummer ne null", -1),

            ('arkivstruktur/mappe/', # både plan og matrikkel
             "nasjonalidentifikator/kommunenummer eq '0101'", -1),

            ('arkivstruktur/mappe/',
             "nasjonalidentifikator/koordinatsystem/kode eq 'EPSG:4326'", -1),

            ('arkivstruktur/mappe/',
             "nasjonalidentifikator/x gt 1.0'", -1),

            # Is this the way to search for author and noekkelord?
            ('arkivstruktur/mappe/',
             "noekkelord/noekkelord eq 'interesting'", -1),

            ('arkivstruktur/mappe/',
             'noekkelord/noekkelord ne null', -1),

            ('arkivstruktur/dokumentbeskrivelse/',
             "forfatter/forfatter eq 'Henrik Ibsen'", -1), # enable when Nikita work

            ('arkivstruktur/mappe/',
             'virksomhetsspesifikkeMetadata/%s eq "one for the team"' % self.vsmkey, -1),
        )

        for s in searches:
            url = self.findRelation('%s%s' % (self.relbaseurl, s[0]))
            searchurl = url + '?$filter=' + quote_plus(s[1]) + '&$top=1'
            if -1 == s[2]:
                failure=self.xfailure
            else:
                failure=self.failure
            if self.verbose:
                print("Searching with %s" % searchurl)
            (body, res) = self.json_get(searchurl)
            if self.verbose:
                print("Search string:", body)
            try:
                searchinfo = json.loads(body)
            except json.decoder.JSONDecodeError as e:
                failure("search %s returned non-json output '%s': %s" %
                             (searchurl, body, str(e)))
                continue
            if self.verbose:
                print("Search result:\n", json.dumps(searchinfo, indent=4))
            if 'results' in searchinfo:
                self.success("search %s worked" % searchurl)
                if 'count' in searchinfo and s[2] <= int(searchinfo['count']):
                    self.success("search %s returned %d items" %
                                 (searchurl, s[2]))
                else:
                    failure("search %s returned %s not %d items" %
                                  (searchurl, searchinfo['count'], s[2]))
            else:
                failure("search %s failed" % searchurl)

    def runtests(self):
        try:
            baseref = self.testBasis()
            self.recursiveHateoas()
            try:
                self.login()
                self.gotlogin = True
                self.success("able to log in using admin/password")
            except n5core.endpoint.LoginFailure as e:
                self.gotlogin = False
                self.failure("unable to log in, operating in read only mode: %s" % e)
            self.recursiveHateoas()

            # Disabled until we figure out exactly what kind of date
            # formats should be supported.
            #self.testDateFormats()

            #self.testAllAttributes()
            self.testNewDocument()
            self.recursiveHateoas()
            self.testNewDocument()
            self.modifyAllCreated()
            self.testMetadata()
            self.testOdataSearch()
            if not self.keeptestdata:
                self.deleteCreated()
        finally:
            print("%d successes, %d failures, %d expected failures"
                  % (len(self.successes.keys()),
                     len(self.failures.keys()),
                     len(self.xfailures.keys())))
        return not (0 == len(self.failures.keys()))
def main():
    t = Noark5Tester()
    return t.runtests()

if __name__ == '__main__':
    if os.path.isdir('.git'):
        call(["git", "rev-parse", "HEAD"])
    exit(main())
